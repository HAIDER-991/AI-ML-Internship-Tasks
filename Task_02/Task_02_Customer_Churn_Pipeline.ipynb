{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement\n",
        "Customer churn is a major challenge for telecom companies. Predicting whether a customer\n",
        "is likely to leave helps businesses take proactive retention measures.\n",
        "\n",
        "### Objective\n",
        "Build a reusable and production-ready machine learning pipeline using Scikit-learn\n",
        "to predict customer churn using the Telco Churn dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "SLoxVN2ap9MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "oCa0kOe5s-aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "WAAsrAQgqFEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert TotalCharges to numeric\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "\n",
        "# Drop missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Encode target variable\n",
        "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n"
      ],
      "metadata": {
        "id": "Y1fjl6uEtId4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[\"customerID\", \"Churn\"])\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
        "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n"
      ],
      "metadata": {
        "id": "geE7sdUAtKma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numerical_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "IMZIwLkAtM29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "v5PxbpePtPC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
        "])\n"
      ],
      "metadata": {
        "id": "ntFXIvGwtRUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
        "])\n"
      ],
      "metadata": {
        "id": "Xif7EebTtTzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params = {\n",
        "    \"classifier__C\": [0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "lr_grid = GridSearchCV(\n",
        "    lr_pipeline,\n",
        "    lr_params,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr_grid.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "ZuR5kM57tWxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {\n",
        "    \"classifier__n_estimators\": [100, 200],\n",
        "    \"classifier__max_depth\": [None, 10, 20]\n",
        "}\n",
        "\n",
        "rf_grid = GridSearchCV(\n",
        "    rf_pipeline,\n",
        "    rf_params,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_grid.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "wxu35jW9tZEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\n{name}\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "evaluate(lr_grid.best_estimator_, \"Logistic Regression\")\n",
        "evaluate(rf_grid.best_estimator_, \"Random Forest\")\n"
      ],
      "metadata": {
        "id": "6FULQehetbYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = rf_grid.best_estimator_\n",
        "\n",
        "joblib.dump(best_model, \"churn_prediction_pipeline.pkl\")\n"
      ],
      "metadata": {
        "id": "PHWymqQntdbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Final Insights\n",
        "- Pipelines ensure clean, reusable, and leakage-free preprocessing.\n",
        "- Random Forest achieved better performance than Logistic Regression.\n",
        "- GridSearchCV improved model performance through tuning.\n",
        "- The exported pipeline can be directly deployed in production.\n"
      ],
      "metadata": {
        "id": "wuq6PgcktfQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Insights\n",
        "- Pipelines ensure clean, reusable, and leakage-free preprocessing.\n",
        "- Random Forest achieved better performance than Logistic Regression.\n",
        "- GridSearchCV improved model performance through tuning.\n",
        "- The exported pipeline can be directly deployed in production.\n"
      ],
      "metadata": {
        "id": "B3rYxqcZthbY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYouAkxTtiHl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}